#CNN识别验证码
## 1. 数据集介绍  
在GenPics文件夹中包含6000张验证码图片，和一个CSV文件，里面包含两列数据，第一列是验证码图片名称，第二列是该图片对应的验证码字母。
## 2. 隐藏层模块  
因为我们使用的是tensorflow的基础API，要是建立一个多层网络的话，会重复写许多代码，所以我们首先将生成卷积层、池化层、全连接层等函数放在一个模块中，之后从这个模块调用函数就可以了。  
**在`layers.py`模块中，有下列这些函数**：  

- weight_variable(shape):生成初始权重，传入形状即可，里面用到了tf.truncated_normal函数，这个函数是生成截断式的正态分布随机数，据说在深度学习中比用tf.random_normal效果更好。  
- bias_variable(shape):生成偏差，也是传入形状即可，偏差值是固定的0.1。  
- conv2d(x, W):对tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')的封装，调用函数书写方便，而且把卷积核的步长也固定了为1步，零填充为'SAME'，这两个参数这样设置后，传入的X第1维和第2维的大小经过卷积后也不会变，使得我们免于计算卷积后的形状大小。  
- max_pool_2x2(x):对tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')，调用函数书写方便，池化器的大小为2X2，步长也固定了为2步，零填充为'SAME'，这样设置后，传入的x第1维和第2维的大小经过池化后会变为原来大小的一半，使得我们容易得出池化后的形状大小。  
- conv_layer(input, shape):按照shape参数生成权重参数和偏差，然后以这些权重参数和偏差对Input进行卷积，调用了上面定义的weight_variable(shape)、bias_variable(shape)和conv2d(x, W)函数，然后最后还对卷积后的输出用Relu函数进行激活，相当于卷积层后加了一个激活层，然后返回这个激活后的数据。  
- full_layer(input, size):按照Input数据的形状第一维数字和size参数生成权重，按照size参数生成偏差，然后返回input与权重的矩阵相乘结果加上偏差。  
## 3. 导入数据  
当要训练的数据量很大的时候，无法一次导入内存，我们就需要分批次的导入数据，这时候就需要用到tensorflow的QueueRunner技术了。  
在`cnn_verification.py`模块中，read_picture函数就是对这个技术的应用：  

- QueueRunner分为三步：将文件名存入读取队列、读取与解码、批处理。  
- 将文件名导入队列需要用到tf.train.string_input_producer函数。  
- 因为数据集是JPEG文件，所以我们用tf.WholeFileReader函数读取。  
- 之后就是解码图片数据，需要用到tf.image.decode_jpeg函数。
- 解码后图片的形状还未定，所以还需使用静态改变形状的办法指定图片的大小为[20,80,3]  
- 然后就可以将解码并转换后得数据放入批处理队列了，这里批处理的大小设置为100。当然也可以往大了设置，看电脑的性能而定。  
## 4. 将验证码字母转换为数字  
验证码图片包含4个字母，但是神经网络无法预测出一个具体的字母，所以需要在CSV文件中，将字母转换为数字。  
处理表格型数据是pandas库的特长，所以我们导入pandas库，将csv数据转化为DataFrame数据结构，然后将每个图片对应的验证码字母转换为一个包含4个数字的列表。  
## 5. 图片名称与数字列表的对应
因为我们从批处理中得到的图片名称列表是图片的原名称，不是要预测的目标值，所以我们要将图片名称与CSV文件中的数字列表对应，还是通过pandas的功能来实现，将名称列表转化为包含数字列表的列表。  
## 6. 神经网络设计  
在`cnn_verification.py`模块中，我们在get_y_predict函数建立了一个卷积层+激活层+池化层+卷积层+激活层+池化层+全连接层+激活层+dropout层+全连接层的神经网络：  

- 这个网络中需要注意的是每次经过一个层，数据形状是怎么变化的。刚开始输入是[100,20,80,3],经过第一层卷积之后，变为[100,20,80,32],再经过第一层池化后，变为[100,10,40,32]，再经过第二层卷积之后，变为[100,10,40,64],再经过第二层池化后，变为[100,5,20,64]。  
- 此时要经过全连接层，所以我们要将数据变为二维，结果变为[100, 5x20x64]。  
- 经过全连接层和激活层之后，这里加入了一个dropout层，是为了防止网络过拟合，所以随机抛弃一些节点，再跟最后一层全连接层做计算。  
- 最后一层全连接层为26x4个节点，因为我们要预测4个数字，每个数字是26个字母中的一个，所以每个数字需要预测26个类别的概率大小，将4个数字的拼接起来就是26x4个类别。  
## 7. 运行网络  
在将tensorflow的张量和操作设计好后，我们就可以在会话中运行网络了。  
在会话中需要注意的是，因为我们是使用QueueRunner技术来读取数据的，所以需要在会话中将线程开启，由这两句代码实现：coord = tf.train.Coordinator()、threads = tf.train.start_queue_runners(sess=sess, coord=coord)。  
最后还要关闭线程，由这两句代码实现：coord.request_stop()、coord.join(threads)。  
在会话中，我们还需要将包含目标值的列表转换为one_hot值，然后改变形状为[-1, 26x4]。
## 8. 训练结果  
最后的训练结果达到了100%的准确率。
![](./pictures/jieguo.png)  